{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structuring COICOP 2018 information for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The COICOP 2018 classification contains unstructured information for its most detailed level of classification. This notebook leverages LLMs in order to structure this information in a format which can be used for similarity search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time # Add delays because of free API rate limits\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "from ftfy import fix_text\n",
    "from unidecode import unidecode\n",
    "\n",
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "from pydantic_ai import Agent\n",
    "from pydantic_ai.models.mistral import MistralModel\n",
    "from pydantic_ai.models.groq import GroqModel\n",
    "\n",
    "from dotenv import dotenv_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio # Fix issues with Jupyter notebook event loop\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import environment variables with API keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dotenv_values(\".env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Pydantic model for parsing the additional information in each COICOP 2018 level 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoicopDetails(BaseModel):\n",
    "    examples: List[str]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read COICOP 2018 definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usecols = [\"code\",\"title\",\"intro\", \"includes\", \"alsoIncludes\"]\n",
    "\n",
    "data_df = pd.read_excel(\n",
    "    \"coicop_2018/COICOP_2018_English_structure.xlsx\", \n",
    "    usecols=usecols,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove exclusion note from the English and French files, rename Spanish columns.\n",
    "\n",
    "Remove (ND), (SD), (D), (S) markings from the class names\n",
    "\n",
    "Filter level 4 classes only for LLMs queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_subclasses(df):\n",
    "    \"\"\"\n",
    "    Process DataFrame with the following operations:\n",
    "    1. Filter rows where Code contains exactly 3 dots\n",
    "    2. Combine description columns\n",
    "    3. Remove classification markers from Description\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Processed DataFrame\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying the original\n",
    "    result_df = df.copy()\n",
    "    \n",
    "    # 1. Select rows where Code has exactly 2 dots\n",
    "    result_df = result_df[result_df['code'].str.count(r'\\.') == 3]\n",
    "    \n",
    "    # 2. Combine description columns\n",
    "    columns_to_concat = [\"intro\", \"includes\", \"alsoIncludes\"]\n",
    "    \n",
    "    def concatenate_non_nan_columns(row):\n",
    "        # Filter out NaN values and convert to string\n",
    "        non_nan_values = [str(row[col]) for col in columns_to_concat if pd.notna(row[col])]\n",
    "        return ' \\n '.join(non_nan_values) if non_nan_values else ''\n",
    "    \n",
    "    result_df['description'] = result_df.apply(concatenate_non_nan_columns, axis=1)\n",
    "    # Fix encoding issues\n",
    "    result_df['description'] = result_df['description'].apply(fix_text)\n",
    "    result_df['description'] = result_df['description'].apply(unidecode)\n",
    "    result_df['description'] = result_df['description'].str.replace(\"_x000D_\", \" \")\n",
    "        \n",
    "    # 3. Remove classification markers from Description\n",
    "    markers_pattern = r'\\s*\\((ND|SD|S|D)\\)'\n",
    "    result_df['title'] = result_df['title'].str.replace(markers_pattern, '', regex=True)\n",
    "    \n",
    "    return result_df[[\"code\", \"title\", \"description\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = process_subclasses(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = data_df.to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mistral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize PydanticAI agent to structure information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model = \"mistral-large-latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MistralModel(model_name=llm_model, api_key=config.get(\"MISTRAL_API_KEY\"))\n",
    "agent = Agent(\n",
    "    model=model,\n",
    "    retries=3,\n",
    "    result_type=CoicopDetails,\n",
    "    system_prompt=(\n",
    "        'You are an expert data curator. You will receive a string of text '\n",
    "        'with examples of items to be included into a certain classification. '\n",
    "        'Your task is to transform this text into a list of self-explainig '\n",
    "        'items descriptions, exploding the examples to the most granular level you can '\n",
    "        'identify in the text. '\n",
    "        'Each item description should contain all necessary information for classification '\n",
    "        'as provided in the original text. Prefer complete descriptions rather than single words. '\n",
    "        'If possible, avoid the use of ambiguous or generic terms such as `other` or `miscellaneous`. '\n",
    "        'Your output should be in the same language as the input text. '\n",
    "        ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run calls to the Agent to extract and format information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "failed_calls = []\n",
    "for i, item in enumerate(data_dict):\n",
    "    # Print every 20 items to show progress\n",
    "    if i % 20 == 0:\n",
    "        print(f\"Processing item {i+1} out of {len(data_dict)}\")\n",
    "    # Add switch to skip none items\n",
    "    if item.get(\"description\") is None:\n",
    "        # No information to parse, just append existing item\n",
    "        results.append(item)\n",
    "        continue\n",
    "    # Time delay to respect API rate limits\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        prompt = \"{}. {}\".format(item.get(\"title\"), item.get(\"description\"))\n",
    "        agent_result = agent.run_sync(prompt, model_settings={'temperature': 0.0})\n",
    "        # Add to results all examples, including the original class name...list concatenation\n",
    "        for ex in [item.get(\"title\")] + agent_result.data.model_dump().get(\"examples\"):\n",
    "            # the new \"Description\" is inserted at the end, so it overwrites the original one\n",
    "            results.append({**item, \"title\": ex})\n",
    "    except Exception as e:\n",
    "        failed_calls.append(item)\n",
    "        print(f\"Error processing item {i+1} out of {len(data_dict)}\")\n",
    "        print(item)\n",
    "        print(e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save results and failed calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.drop(columns=[\"description\"]).to_csv(\n",
    "    \"results/coicop2018_{}_{}.csv\".format(\n",
    "        llm_model,\n",
    "        datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")),\n",
    "    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_df = pd.DataFrame(failed_calls)\n",
    "failed_df.to_csv(\n",
    "    \"results/failed_coicop2018_{}_{}.csv\".format(\n",
    "        llm_model,\n",
    "        datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")),\n",
    "    index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llama 3 on Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model = \"llama3-70b-8192\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GroqModel(\n",
    "    model_name=llm_model, \n",
    "    api_key=config.get(\"GROQ_API_KEY\"))\n",
    "agent = Agent(\n",
    "    model=model,\n",
    "    retries=3,\n",
    "    result_type=CoicopDetails,\n",
    "    system_prompt=(\n",
    "        'You are an expert data curator. You will receive a string of text '\n",
    "        'with examples of items to be included into a certain classification. '\n",
    "        'Your task is to transform this text into a list of self-explainig '\n",
    "        'items descriptions, exploding the examples to the most granular level you can '\n",
    "        'identify in the text. '\n",
    "        'Each item description should contain all necessary information for classification '\n",
    "        'as provided in the original text. Prefer complete descriptions rather than single words. '\n",
    "        'If possible, avoid the use of ambiguous or generic terms such as `other` or `miscellaneous`. '\n",
    "        'Your output should be in the same language as the input text. '\n",
    "        ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "failed_calls = []\n",
    "for i, item in enumerate(data_dict):\n",
    "    # Print every 20 items to show progress\n",
    "    if i % 20 == 0:\n",
    "        print(f\"Processing item {i+1} out of {len(data_dict)}\")\n",
    "    # Add switch to skip none items\n",
    "    if item.get(\"description\") is None:\n",
    "        # No information to parse, just append existing item\n",
    "        results.append(item)\n",
    "        continue\n",
    "    # Time delay to respect API rate limits\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        prompt = \"{}. {}\".format(item.get(\"title\"), item.get(\"description\"))\n",
    "        agent_result = agent.run_sync(prompt, model_settings={'temperature': 0.0})\n",
    "        # Add to results all examples, including the original class name...list concatenation\n",
    "        for ex in [item.get(\"title\")] + agent_result.data.model_dump().get(\"examples\"):\n",
    "            # the new \"Description\" is inserted at the end, so it overwrites the original one\n",
    "            results.append({**item, \"title\": ex})\n",
    "    except Exception as e:\n",
    "        failed_calls.append(item)\n",
    "        print(f\"Error processing item {i+1} out of {len(data_dict)}\")\n",
    "        print(item)\n",
    "        print(e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.drop(columns=[\"description\"]).to_csv(\n",
    "    \"results/coicop2018_{}_{}.csv\".format(\n",
    "        llm_model,\n",
    "        datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")),\n",
    "    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_df = pd.DataFrame(failed_calls)\n",
    "failed_df.to_csv(\n",
    "    \"results/failed_coicop2018_{}_{}.csv\".format(\n",
    "        llm_model,\n",
    "        datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")),\n",
    "    index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixtral on Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model = \"mixtral-8x7b-32768\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GroqModel(\n",
    "    model_name=llm_model, \n",
    "    api_key=config.get(\"GROQ_API_KEY\"))\n",
    "agent = Agent(\n",
    "    model=model,\n",
    "    retries=3,\n",
    "    result_type=CoicopDetails,\n",
    "    system_prompt=(\n",
    "        'You are an expert data curator. You will receive a string of text '\n",
    "        'with examples of items to be included into a certain classification. '\n",
    "        'Your task is to transform this text into a list of self-explainig '\n",
    "        'items descriptions, exploding the examples to the most granular level you can '\n",
    "        'identify in the text. '\n",
    "        'Each item description should contain all necessary information for classification '\n",
    "        'as provided in the original text. Prefer complete descriptions rather than single words. '\n",
    "        'If possible, avoid the use of ambiguous or generic terms such as `other` or `miscellaneous`. '\n",
    "        'Your output should be in the same language as the input text. '\n",
    "        ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "failed_calls = []\n",
    "for i, item in enumerate(data_dict):\n",
    "    # Print every 20 items to show progress\n",
    "    if i % 20 == 0:\n",
    "        print(f\"Processing item {i+1} out of {len(data_dict)}\")\n",
    "    # Add switch to skip none items\n",
    "    if item.get(\"description\") is None:\n",
    "        # No information to parse, just append existing item\n",
    "        results.append(item)\n",
    "        continue\n",
    "    # Time delay to respect API rate limits\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        prompt = \"{}. {}\".format(item.get(\"title\"), item.get(\"description\"))\n",
    "        agent_result = agent.run_sync(prompt, model_settings={'temperature': 0.0})\n",
    "        # Add to results all examples, including the original class name...list concatenation\n",
    "        for ex in [item.get(\"title\")] + agent_result.data.model_dump().get(\"examples\"):\n",
    "            # the new \"Description\" is inserted at the end, so it overwrites the original one\n",
    "            results.append({**item, \"title\": ex})\n",
    "    except Exception as e:\n",
    "        failed_calls.append(item)\n",
    "        print(f\"Error processing item {i+1} out of {len(data_dict)}\")\n",
    "        print(item)\n",
    "        print(e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.drop(columns=[\"description\"]).to_csv(\n",
    "    \"results/coicop2018_{}_{}.csv\".format(\n",
    "        llm_model,\n",
    "        datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")),\n",
    "    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_df = pd.DataFrame(failed_calls)\n",
    "failed_df.to_csv(\n",
    "    \"results/failed_coicop2018_{}_{}.csv\".format(\n",
    "        llm_model,\n",
    "        datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")),\n",
    "    index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_files = [f for f in os.listdir(\"results/\") if f.startswith(\"coicop2018\") and f.endswith(\".csv\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list = []\n",
    "for f in result_files:\n",
    "    temp_df = pd.read_csv(os.path.join(\"results\", f))\n",
    "    results_list.append(temp_df)\n",
    "\n",
    "results_df = pd.concat(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[\"code\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize to lowercase and remove all \"other\" labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase\n",
    "results_df[\"title\"] = results_df[\"title\"].str.lower()\n",
    "# Remove duplicates\n",
    "results_df = results_df.drop_duplicates(ignore_index=True)\n",
    "# Remove items with \"other\" or \"miscellaneous\"\n",
    "results_df = results_df[~results_df[\"title\"].str.contains(\"other|miscellaneous\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[\"code\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\n",
    "    \"results/consolidated_coicop2018_{}.csv\".format(\n",
    "        datetime.now().strftime(\"%Y-%m-%d\")), \n",
    "    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
